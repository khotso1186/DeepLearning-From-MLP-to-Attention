{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install python-levenshtein\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more information on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "# Install CTCBeamDecoder Pacakge\n",
    "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
    "!pip install wget\n",
    "%cd ctcdecode\n",
    "!pip install .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "sys.path.append(\"./hw3p2/\")\n",
    "from phoneme_list import N_STATES, N_PHONEMES, PHONEME_LIST, PHONEME_MAP\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from ctcdecode import CTCBeamDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-levenshtein in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.12.0)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from python-levenshtein) (39.1.0)\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install Lev Package\n",
    "!pip install python-levenshtein\n",
    "import Levenshtein as lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataX = dataset[0]\n",
    "        self.dataY = dataset[1] if len(dataset) == 2 else None\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.dataX[idx]).float(), torch.from_numpy(self.dataY[idx] + 1 if self.dataY is not None else np.array([-1])).int() # add 1 to label to account for blank\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataX)\n",
    "\n",
    "    \n",
    "# Model that takes packed sequences in training\n",
    "class PackedModel(nn.Module):\n",
    "    def __init__(self, hidden_size, nlayers, out_size=47, embed_size=40):\n",
    "        super(PackedModel, self).__init__()\n",
    "        self.nlayers = nlayers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.out_size = out_size\n",
    "        self.cnns = torch.nn.Sequential(\n",
    "            nn.Conv1d(self.embed_size, self.hidden_size, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(self.hidden_size),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.rnns = nn.LSTM(input_size=self.hidden_size,\n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers=3,\n",
    "                            bias=True,\n",
    "                            batch_first=True,\n",
    "                            dropout=0.2, # regularization\n",
    "                            bidirectional=True)\n",
    "        self.hidden2label = torch.nn.Sequential(\n",
    "            nn.Linear(self.hidden_size*2, self.hidden_size),\n",
    "            nn.Linear(self.hidden_size, self.out_size))\n",
    "    def forward(self, x, xLens): # x dim (B, T_in, C_in=40)\n",
    "        x_cnn_input = x.permute(0, 2, 1) # (B, C_in, T_in)\n",
    "        x_post_cnn = self.cnns(x_cnn_input) # (B, C_out, T_out)\n",
    "        x_rnn_in = x_post_cnn.permute(2, 0, 1) # (T, B, C_out)\n",
    "        x_packed = pack_padded_sequence(x_rnn_in, xLens, enforce_sorted=False)\n",
    "        out_packed, hidden = self.rnns(x_packed)\n",
    "        out, out_lens = pad_packed_sequence(out_packed, batch_first=True) # (B, T, C)\n",
    "        \n",
    "        # Log softmax after output layer is required since nn.CTCLoss expect log prob\n",
    "        out_prob = self.hidden2label(out).log_softmax(2) # (B, T, Classes=47)\n",
    "        \n",
    "        # Permute to fit for input format of CTCLoss\n",
    "        out_prob = out_prob.permute(1, 0, 2) #torch.transpose(out_prob, 0, 1) # (T, B, C)\n",
    "        \n",
    "        # TODO: calculate new xLens\n",
    "        return out_prob, xLens\n",
    "\n",
    "    \n",
    "def getLoaders(train, dev, test, batchSize):\n",
    "    trainX, trainY = train\n",
    "    devX, devY = dev\n",
    "    testX, _ = test\n",
    "    \n",
    "    print(\"*** Create data loader ***\")\n",
    "    # Train\n",
    "    train_loader_args = dict(shuffle=True, batch_size=batchSize, num_workers=8, collate_fn=pad_collate, pin_memory=True)\n",
    "    train_loader = DataLoader(MyDataset(train), **train_loader_args)\n",
    "    \n",
    "    # Dev\n",
    "    dev_loader = DataLoader(MyDataset(dev), **train_loader_args)\n",
    "    \n",
    "    # Test\n",
    "    test_loader_args = dict(shuffle=False, batch_size=batchSize, num_workers=8, collate_fn=pad_collate, pin_memory=True)\n",
    "    test_loader = DataLoader(MyDataset(test), **test_loader_args)\n",
    "    \n",
    "    return train_loader, dev_loader, test_loader\n",
    "\n",
    "\n",
    "def decode(output_probs, dataLens, beamWidth):\n",
    "    decoder = CTCBeamDecoder(labels=PHONEME_MAP, beam_width=beamWidth,\n",
    "                            num_processes=os.cpu_count(), log_probs_input=True)\n",
    "    output_probs = torch.transpose(output_probs, 0, 1) # post transpose: (B, T, C=47)\n",
    "    output, _, _, out_seq_len = decoder.decode(output_probs, dataLens) # output dim: (BatchSize, Beamwith, T), Out_seq_len dim (batchsize, bewmwidth)\n",
    "    decodedListShort = []\n",
    "    decodedListLong = []\n",
    "    for b in range(output_probs.size(0)):\n",
    "        currDecode = \"\"\n",
    "        if out_seq_len[b][0] != 0:\n",
    "            currDecodeShort = \"\".join([PHONEME_MAP[i] for i in output[b, 0, :out_seq_len[b][0]]])\n",
    "            currDecodeLong = \"\".join([PHONEME_LIST[i] for i in output[b, 0, :out_seq_len[b][0]]])\n",
    "        decodedListShort.append(currDecodeShort)\n",
    "        decodedListLong.append(currDecodeLong)\n",
    "        \n",
    "    return decodedListShort, decodedListLong\n",
    "\n",
    "\n",
    "def idx2phonemes(target):\n",
    "    return \"\".join([PHONEME_MAP[x] for x in target])\n",
    "\n",
    "def calculateLevScore(w1, w2):\n",
    "    return lev.distance(w1.replace(\" \", \"\"), w2.replace(\" \", \"\"))\n",
    "\n",
    "def train_epoch(mode, data_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target, dataLens, targetLens) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data, target, dataLens, targetLens = data.cuda(), target.cuda(), dataLens.cuda(), targetLens.cuda()\n",
    "\n",
    "        output, dataLens_new = model(data, dataLens) # out dim: (T, B, C)\n",
    "        loss = criterion(output, # (T, B, C) T is the largest len in the batch\n",
    "                         target, # (B, S), S is the largest len in the batch\n",
    "                         dataLens_new, # (B,), len of sequences in output_log_prob\n",
    "                         targetLens) # (B,)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(\"Epoch: {}\\tBatch: {}\\tTimestamp: {}\".format(epoch, batch_idx, time.time() - start_time))\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        del data\n",
    "        del target\n",
    "        del dataLens\n",
    "        del targetLens\n",
    "\n",
    "        \n",
    "def test_epoch(model, data_loader, epoch, decodeMode=False):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_charErr = 0.0\n",
    "        totalSampleCnt = 0\n",
    "        \n",
    "        for batch_idx, (data, target, dataLens, targetLens) in enumerate(data_loader):\n",
    "            data, target, dataLens, targetLens = data.cuda(), target.cuda(), dataLens.cuda(), targetLens.cuda()\n",
    "            output, dataLens_new = model(data, dataLens)\n",
    "            loss = criterion(output,\n",
    "                             target,\n",
    "                             dataLens_new,\n",
    "                             targetLens)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            totalSampleCnt += len(data)\n",
    "            if decodeMode:\n",
    "                decodedStringsShort, decodedStringsLong = decode(output, dataLens, hyper[\"beamWidth\"])\n",
    "                targetStrings = [idx2phonemes(i) for i in target]\n",
    "                for i in range(len(targetStrings)):\n",
    "                    currCharErr = calculateLevScore(decodedStringsShort[i], targetStrings[i])\n",
    "                    running_charErr += currCharErr\n",
    "            if batch_idx % 50 == 0:\n",
    "                print(\"Epoch: {}\\tBatch: {}\\tTimestamp: {}\".format(epoch, batch_idx, time.time() - start_time))\n",
    "            torch.cuda.empty_cache()\n",
    "            del data\n",
    "            del target\n",
    "            del dataLens\n",
    "            del targetLens\n",
    "        loss_per_sample = running_loss / len(data_loader)\n",
    "        dist_per_sample = running_charErr / len(data_loader)\n",
    "        return loss_per_sample, dist_per_sample\n",
    "                \n",
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "    resShort = np.array([])\n",
    "    resLong = np.array([])\n",
    "    start_time = time.time()\n",
    "    totalSampleCnt = 0\n",
    "    for batch_idx, (data, target, dataLens, targetLens) in enumerate(data_loader):\n",
    "        data, target, dataLens, targetLens = data.cuda(), target.cuda(), dataLens.cuda(), targetLens.cuda()\n",
    "        output, dataLens_new = model(data, dataLens)\n",
    "        \n",
    "        decodedStringsShort, decodedStringsLong = decode(output, dataLens, hyper[\"beamWidth\"])\n",
    "        resShort = np.concatenate((resShort, decodedStringsShort))\n",
    "        resLong = np.concatenate((resLong, decodedStringsLong))\n",
    "        print(\"Predict \\tBatch: {}\\tTimestamp: {}\".format(batch_idx, time.time() - start_time))\n",
    "        torch.cuda.empty_cache()\n",
    "        del data\n",
    "        del target\n",
    "        del dataLens\n",
    "        del targetLens\n",
    "        \n",
    "    return resShort, resLong\n",
    "\n",
    "\n",
    "def pad_collate(batch):\n",
    "    # reference from tutorial: https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html\n",
    "    # sortedBatch = batch # sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
    "    inputs = [x[0] for x in batch]\n",
    "    targets = [x[1] for x in batch]\n",
    "    inputs_pad = pad_sequence(inputs, batch_first=True) # dim (B, T, C) since batch_first is true, (T, B, C) if false\n",
    "    targets_pad = pad_sequence(targets, batch_first=True)\n",
    "    inputs_lens = torch.LongTensor([len(x) for x in inputs])\n",
    "    targets_lens = torch.LongTensor([len(x) for x in targets])\n",
    "    return inputs_pad, targets_pad, inputs_lens, targets_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(hyper):\n",
    "    # Load datasets\n",
    "    print(\"*** Load raw data ***\")\n",
    "    train = (np.load(os.path.join(hyper[\"dataPath\"], \"wsj0_train\"), allow_pickle=True),\n",
    "            (np.load(os.path.join(hyper[\"dataPath\"], \"wsj0_train_merged_labels.npy\"), allow_pickle=True)))\n",
    "    dev = (np.load(os.path.join(hyper[\"dataPath\"], \"wsj0_dev.npy\"), allow_pickle=True),\n",
    "            (np.load(os.path.join(hyper[\"dataPath\"], \"wsj0_dev_merged_labels.npy\"), allow_pickle=True)))\n",
    "    test = (np.load(os.path.join(hyper[\"dataPath\"], \"wsj0_test\"), allow_pickle=True), None)\n",
    "    \n",
    "    # Get data loaders\n",
    "    train_loader, dev_loader, test_loader = getLoaders(train, dev, test, hyper[\"batchSize\"])\n",
    "    \n",
    "    # Set random seed\n",
    "    np.random.seed(hyper[\"seed\"])\n",
    "    torch.manual_seed(hyper[\"seed\"])\n",
    "    torch.cuda.manual_seed(hyper[\"seed\"])\n",
    "    \n",
    "    # Add blank space for phoneme map\n",
    "    PHONEME_MAP = [\" \"] + PHONEME_MAP\n",
    "    PHONEME_LIST = [\" \"] + PHONEME_LIST\n",
    "    \n",
    "    # Create the model and define the Loss an Optimizer\n",
    "    print(\"*** Create the model and define Loss and Optimizer ***\")\n",
    "    model = PackedModel(hidden_size=hyper[\"hiddenSize\"], nlayers=hyper[\"nlayers\"], out_size=47, embed_size=40)\n",
    "    checkpoint = torch.load(hyper[\"savedCheckpoint\"])\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyper[\"lr\"], weight_decay=hyper[\"weightDecay\"])\n",
    "    criterion = nn.CTCLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1, verbose=True)\n",
    "    model.cuda()\n",
    "    print(model)\n",
    "    \n",
    "    # Train the model for N epochs\n",
    "    for i in range(hyper[\"nEpochs\"]):\n",
    "        # Print current learnng rate\n",
    "        for prarm_group in optimizer.param_groups:\n",
    "            print(\"Current lr: \\t{}\".format(prarm_group[\"lr\"]))\n",
    "\n",
    "        # Trian\n",
    "        print(\"Train\\tEpoch: {}\".format(i))\n",
    "        startTime = time.time()\n",
    "        train_epoch(model, train_loader, criterion, optimizer, i)\n",
    "\n",
    "        # Evaluate\n",
    "        print(\"Evaluate Train \\tEpoch: {}\".format(i))\n",
    "        train_lossPerSample, train_distPerSample = test_epoch(model, train_loader, i)\n",
    "        print('Train_LossPerSample: {:.4f}\\tTrain_DistPerSample: {:.4f}'.format(\n",
    "            train_lossPerSample, train_distPerSample))\n",
    "        print(\"Evaluate Dev \\tEpoch: {}\".format(i))\n",
    "        dev_lossPerSample, dev_distPerSample = test_epoch(model, dev_loader, i)\n",
    "        print('Dev_LossPerSample: {:.4f}\\tDev_DistPerSample: {:.4f}'.format(\n",
    "            dev_lossPerSample, dev_distPerSample))\n",
    "\n",
    "        scheduler.step(dev_lossPerSample)\n",
    "\n",
    "        # Save checkpoint\n",
    "        print(\"*** Saving Checkpoint ***\")\n",
    "        path = \"{}CNN1_Cont_Epoch{}.txt\".format(hyper[\"checkpointPath\"], i)\n",
    "        torch.save({\n",
    "            \"epoch\":i,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()}, path)\n",
    "        print(\"=\"*20 + \" Epoch {} took {}s\".format(i, time.time()-startTime) + \"=\"*20)\n",
    "    \n",
    "    # Predict and save\n",
    "    resShort, resLong = predict(model, test_loader)\n",
    "    np.save(hyper[\"testLabelName\"], resShort)\n",
    "    idxs = np.array(list(range(len(resShort))))\n",
    "    df = pd.DataFrame({\"id\" : idxs, \"Predicted\" : resShort})\n",
    "    df.to_csv(hyper[\"testLabelCSVfn\"], index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Load raw data ***\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-768b86daa368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;34m\"savedCheckpoint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"./checkpoint/CNN1_Cont_Epoch6.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     }\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-144-8f20b05189d4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(hyper)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Load datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*** Load raw data ***\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     train = (np.load(os.path.join(hyper[\"dataPath\"], \"wsj0_train\"), allow_pickle=True),\n\u001b[0m\u001b[1;32m      5\u001b[0m             (np.load(os.path.join(hyper[\"dataPath\"], \"wsj0_train_merged_labels.npy\"), allow_pickle=True)))\n\u001b[1;32m      6\u001b[0m     dev = (np.load(os.path.join(hyper[\"dataPath\"], \"wsj0_dev.npy\"), allow_pickle=True),\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 433\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    hyper = {\n",
    "        \"dataPath\": \"./hw3p2\",\n",
    "        \"batchSize\": 64,\n",
    "        \"lr\":5e-4,\n",
    "        \"weightDecay\":5e-5,\n",
    "        \"hiddenSize\": 256,\n",
    "        \"nlayers\":3,\n",
    "        \"nEpochs\":20,\n",
    "        \"beamWidth\":30,\n",
    "        \"checkpointPath\": \"./checkpoint/\",\n",
    "        \"seed\":20,\n",
    "        \"testLabelName\" : \"./data/predicted.npy\",\n",
    "        \"testLabelCSVfn\": \"./data/predicted.csv\",\n",
    "        \"savedCheckpoint\": \"./checkpoint/CNN1_Cont_Epoch6.txt\"\n",
    "    }\n",
    "    main(hyper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
