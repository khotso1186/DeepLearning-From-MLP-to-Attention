{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "import PIL\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hyper = {\n",
    "    \"task\": \"Classification\",\n",
    "    \"bottleneckSetting\": [[1, 16, 1, 1], # t, c, n, s\n",
    "                          [6, 24, 2, 1],\n",
    "                          [6, 32, 3, 2],\n",
    "                          [6, 64, 4, 1],\n",
    "                          [6, 96, 3, 2],\n",
    "                          [6, 160, 3, 1],\n",
    "                          [6, 320, 1, 1]],\n",
    "    \"nEpochs\":50,\n",
    "    \"batchSize\":256,\n",
    "    \"lr\":0.001,#1e-3,\n",
    "    \"dataPath\": \"./11-785hw2p2-s20\",\n",
    "    \"checkpoingPath\": \"./checkpoint/ContContInitWeight_BaselineSGD_StepLR_Epoch4.txt\",\n",
    "    \"classifyTestImgFolderPath\": \"./11-785hw2p2-s20/test_classification/medium/\",\n",
    "    \"classifyTestListPath\": \"./11-785hw2p2-s20/test_order_classification.txt\",\n",
    "    \"verifyImgFolderPath\": \"./11-785hw2p2-s20/validation_verification/\",\n",
    "    \"verifyPairListPath\": \"./11-785hw2p2-s20/validation_trials_verification.txt\",\n",
    "    \"verifyTestPairListPath\": \"./11-785hw2p2-s20/test_trials_verification_student.txt\",\n",
    "    \"verifyTestImgFolderPath\": \"./11-785hw2p2-s20/test_verification/\",\n",
    "    \"weightDirName\": \"./checkpoint/\",\n",
    "    \"testClassLabelName\":\"./output/test_class_labels.npy\",\n",
    "    \"testClassLabelCSVfn\":\"./output/test_class_labels.csv\",\n",
    "    \"testVeriLabelName\":\"./output/test_veri_labels.npy\",\n",
    "    \"testVeriLabelCSVfn\":\"./output/test_veri_labels.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDatasetTestClassify(Dataset):\n",
    "    # Create custom Dataset\n",
    "    def __init__(self, testFN, testImgFolderPath):\n",
    "        self.imgFolderPath = testImgFolderPath\n",
    "        with open(testFN) as f:\n",
    "            self.fileList = [line.rstrip() for line in f]\n",
    "    def __len__(self):\n",
    "        return len(self.fileList)\n",
    "    def __getitem__(self, idx):\n",
    "        img = PIL.Image.open(self.imgFolderPath + self.fileList[idx])\n",
    "        img = transforms.ToTensor()(img)\n",
    "        return img, -1\n",
    "    def getFileList(self):\n",
    "        return self.fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDatasetVerify(Dataset):\n",
    "    # Create dataset for validation of verification tast\n",
    "    def __init__(self, pairFN, imgFolderPath):\n",
    "        self.imgFolderPath = imgFolderPath\n",
    "        with open(pairFN) as f:\n",
    "            self.pairList = [line.rstrip() for line in f]\n",
    "    def __len__(self):\n",
    "        return len(self.pairList)\n",
    "    def __getitem__(self, idx):\n",
    "        items = self.pairList[idx].split()\n",
    "        fn1, fn2 = items[0], items[1]\n",
    "        img1 = PIL.Image.open(self.imgFolderPath + fn1)\n",
    "        img2 = PIL.Image.open(self.imgFolderPath + fn2)\n",
    "        img1 = transforms.ToTensor()(img1)\n",
    "        img2 = transforms.ToTensor()(img2)\n",
    "        if len(items) == 3: # validation\n",
    "            return img1, img2, int(items[2])\n",
    "        else: # test\n",
    "            return img1, img2, -1\n",
    "    def getPairList(self):\n",
    "        return self.pairList\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_3x3_bn_relu(inChannel, outChannel, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inChannel, outChannel, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(outChannel),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "def conv2d_1x1_bn_relu(inChannel, outChannel):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inChannel, outChannel, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(outChannel),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, inChannel, outChannel, stride, expandT):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.shouldSkip = self.stride == 1 and inChannel == outChannel\n",
    "        hiddenDim = int(inChannel * expandT)\n",
    "        self.conv = nn.Sequential(\n",
    "            # 1 x 1 expansion layer + bn + ReLU6\n",
    "            nn.Conv2d(inChannel, hiddenDim, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(hiddenDim),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            # 3 x 3 depthwise conv + bn + ReLU6\n",
    "            nn.Conv2d(hiddenDim, hiddenDim, 3, self.stride, 1, groups=hiddenDim, bias=False),\n",
    "            nn.BatchNorm2d(hiddenDim),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            # 1 x 1 projection layer + bn\n",
    "            nn.Conv2d(hiddenDim, outChannel, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(outChannel)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # only skip connnection when stride==1 and inChannel==outChannel\n",
    "        if self.shouldSkip:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, inputSize, bottlesSetting, numClasses, feat_dim=1280):\n",
    "        super(Network, self).__init__()\n",
    "        block = BottleNeck\n",
    "        firstChannel = 32\n",
    "        lastChannel = 1280\n",
    "        blocks = [conv2d_3x3_bn_relu(3, firstChannel, 1)]\n",
    "        # build MobileNet bottlenecks\n",
    "        bottleInChannel = firstChannel\n",
    "        for t, c, n, s in bottlesSetting:\n",
    "            bottleOutChannel = c\n",
    "            for i in range(n):\n",
    "                if i == 0: # the first layer in a sequence\n",
    "                    blocks.append(block(bottleInChannel, bottleOutChannel, s, t))\n",
    "                else:\n",
    "                    blocks.append(block(bottleInChannel, bottleOutChannel, 1, t))\n",
    "                bottleInChannel = bottleOutChannel\n",
    "        # build the conv2d 1x1 layer\n",
    "        blocks.append(conv2d_1x1_bn_relu(bottleInChannel, lastChannel))\n",
    "        self.net = nn.Sequential(*blocks)\n",
    "        \n",
    "        # built classifier\n",
    "        self.classifier = nn.Linear(lastChannel, numClasses)\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(lastChannel, numClasses)\n",
    "#         )\n",
    "         \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        output = nn.functional.adaptive_avg_pool2d(x, 1).reshape(x.shape[0], -1) # flatten\n",
    "        classification_out = self.classifier(output)\n",
    "        embedding_out = output\n",
    "        return embedding_out, classification_out\n",
    "        \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif type(m) == nn.BatchNorm2d:\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, 0, 0.01)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(dataDir):\n",
    "    img_list = []\n",
    "    for root, directories, filenames in os.walk(dataDir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                filei = os.path.join(root, filename)\n",
    "                img_list.append(filei)\n",
    "    print(\"{} # Images\".format(len(img_list)))\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoaders(trainDS, devDS, testDS, batchS):\n",
    "    print(\"*** Create data loader ***\")\n",
    "    \n",
    "    # Train\n",
    "    loader_args = dict(shuffle=True, batch_size=batchS, num_workers=8, pin_memory=True)\n",
    "    train_loader = DataLoader(trainDS, **loader_args)\n",
    "    \n",
    "    # Dev\n",
    "    dev_loader = DataLoader(devDS, **loader_args)\n",
    "    \n",
    "    # Test\n",
    "    test_loader_args = dict(shuffle=False, batch_size=100, num_workers=1, pin_memory=True)\n",
    "    test_loader = DataLoader(testDS, **test_loader_args)\n",
    "    \n",
    "    return train_loader, dev_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, criterion, optimizer, epoch): #task=\"Classification\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        outputs = model(data)[1]\n",
    "        loss = criterion(outputs, target)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print(\"Epoch: {}\\tBatch: {}\\tTimestamp: {}\".format(epoch, batch_idx, time.time() - start_time))\n",
    "        \n",
    "        # clear computation cache\n",
    "        torch.cuda.empty_cache()\n",
    "        del data\n",
    "        del target\n",
    "        del loss\n",
    "    end_time = time.time()\n",
    "    running_loss = running_loss / len(data_loader)\n",
    "    return running_loss\n",
    "\n",
    "def testClassify(model, test_loader, epoch):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0.0\n",
    "        total_predictions = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            outputs = model(data.float())[1]\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, target.long()).detach()\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted==target).sum().item()\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % 500 == 0:\n",
    "                print(\"Epoch: {}\\tBatch: {}\\tTimestamp: {}\".format(epoch, batch_idx, time.time()-start_time))\n",
    "            del data\n",
    "            del target\n",
    "        running_loss /= len(test_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        return running_loss, acc\n",
    "\n",
    "\n",
    "def testVerify(model, vLoader):\n",
    "    similarity = np.array([])\n",
    "    true = np.array([])\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        for batch_idx, (imgs1, imgs2, targets) in enumerate(vLoader):\n",
    "            imgs1, imgs2, targets = imgs1.cuda(), imgs2.cuda(), targets.cuda()\n",
    "            # find cos similarity between embeddings\n",
    "            imgs1Embed = model(imgs1.float())[0]\n",
    "            imgs2Embed = model(imgs2.float())[0]\n",
    "            sim = F.cosine_similarity(imgs1Embed, imgs2Embed) \n",
    "            similarity = np.concatenate((similarity, sim.cpu().numpy().reshape(-1)))\n",
    "            true = np.concatenate((true, targets.cpu().numpy().reshape(-1)))\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\"Batch: {}\\t Timestamp:{}\".format(batch_idx, time.time()-start_time))\n",
    "            del imgs1\n",
    "            del imgs2\n",
    "            del targets\n",
    "    return similarity, true\n",
    "            \n",
    "\n",
    "def predictLabels(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        res = np.array([])\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            outputs = model(data)[1]\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            res = np.concatenate((res, predicted.cpu().numpy().reshape(-1)))\n",
    "            del data\n",
    "            del target\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Load raw data ***\n",
      "train data stat: 822155 images \t 2300 classes\n",
      "dev data stat: 4600 images \t 2300 classes\n",
      "test data stat: 4600 images\n",
      "*** Create data loader ***\n"
     ]
    }
   ],
   "source": [
    "dataFolder = hyper['dataPath']\n",
    "wegithDirName = hyper['weightDirName']\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"*** Load raw data ***\")\n",
    "train = datasets.ImageFolder(root=dataFolder+\"/train_data/medium\",\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor()]))\n",
    "\n",
    "dev = datasets.ImageFolder(root=dataFolder+\"/validation_classification/medium\",\n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Load custom dataset for test since it does not follow ImageFolder structure\n",
    "test = MyDatasetTestClassify(hyper[\"classifyTestListPath\"], hyper[\"classifyTestImgFolderPath\"])\n",
    "\n",
    "print(\"train data stat: {} images \\t {} classes\".format(train.__len__(), len(train.classes)))\n",
    "print(\"dev data stat: {} images \\t {} classes\".format(dev.__len__(), len(dev.classes)))\n",
    "print(\"test data stat: {} images\".format(test.__len__()))\n",
    "\n",
    "# Get data loaders\n",
    "train_loader, dev_loader, test_loader = getLoaders(train, dev, test, hyper[\"batchSize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__getitem__(1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Create the model and define  Loss and Optimizer ***\n",
      "Network(\n",
      "  (net): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): BottleNeck(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU6(inplace=True)\n",
      "        (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Sequential(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=1280, out_features=2300, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the model and define the Loss and Optimizer\n",
    "print(\"*** Create the model and define  Loss and Optimizer ***\")\n",
    "inputSize = train.__len__()         # number of train input images\n",
    "outputSize = len(train.classes)     # number of unique face classes\n",
    "model = Network(inputSize, hyper[\"bottleneckSetting\"], outputSize)\n",
    "# model.apply(init_weights)\n",
    "checkpoint = torch.load(hyper[\"checkpoingPath\"])\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=hyper[\"lr\"], momentum=0.9,\\\n",
    "                      nesterov=True, weight_decay=5e-4)\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.8, patience=1)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.9, step_size=1)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Train the model for N epochs ***\n",
      "Current lr: \t0.001\n",
      "Train\tEpoch: 0\n",
      "Epoch: 0\tBatch: 0\tTimestamp: 0.9484448432922363\n",
      "Epoch: 0\tBatch: 1000\tTimestamp: 497.70069432258606\n",
      "Epoch: 0\tBatch: 2000\tTimestamp: 1011.2534255981445\n",
      "Epoch: 0\tBatch: 3000\tTimestamp: 1526.0770795345306\n",
      "Classify Train \tEpoch: 0\n",
      "Epoch: 0\tBatch: 0\tTimestamp: 0.6695742607116699\n",
      "Epoch: 0\tBatch: 500\tTimestamp: 53.67986011505127\n",
      "Epoch: 0\tBatch: 1000\tTimestamp: 106.7500433921814\n",
      "Epoch: 0\tBatch: 1500\tTimestamp: 159.83489513397217\n",
      "Epoch: 0\tBatch: 2000\tTimestamp: 212.99435114860535\n",
      "Epoch: 0\tBatch: 2500\tTimestamp: 266.1447112560272\n",
      "Epoch: 0\tBatch: 3000\tTimestamp: 319.3462505340576\n",
      "Classify Dev \tEpoch: 0\n",
      "Epoch: 0\tBatch: 0\tTimestamp: 0.5989861488342285\n",
      "Train Loss: 0.7964\tTrain Accuracy: 84.6764\tVal Loss: 1.3993\tVal Accuracy: 71.0217\n",
      "*** Saving Checkpoint ***\n",
      "==================== Epoch 0 took 1979.2950837612152s====================\n",
      "Current lr: \t0.001\n",
      "Train\tEpoch: 1\n",
      "Epoch: 1\tBatch: 0\tTimestamp: 0.8218810558319092\n",
      "Epoch: 1\tBatch: 1000\tTimestamp: 516.5645935535431\n",
      "Epoch: 1\tBatch: 2000\tTimestamp: 1031.61789894104\n",
      "Epoch: 1\tBatch: 3000\tTimestamp: 1546.7350289821625\n",
      "Classify Train \tEpoch: 1\n",
      "Epoch: 1\tBatch: 0\tTimestamp: 0.702444314956665\n",
      "Epoch: 1\tBatch: 500\tTimestamp: 53.831068992614746\n",
      "Epoch: 1\tBatch: 1000\tTimestamp: 106.97866177558899\n",
      "Epoch: 1\tBatch: 1500\tTimestamp: 160.0663435459137\n",
      "Epoch: 1\tBatch: 2000\tTimestamp: 213.1629729270935\n",
      "Epoch: 1\tBatch: 2500\tTimestamp: 266.27919030189514\n",
      "Epoch: 1\tBatch: 3000\tTimestamp: 319.3638868331909\n",
      "Classify Dev \tEpoch: 1\n",
      "Epoch: 1\tBatch: 0\tTimestamp: 0.6212379932403564\n",
      "Train Loss: 0.7923\tTrain Accuracy: 84.4910\tVal Loss: 1.3995\tVal Accuracy: 70.3913\n",
      "*** Saving Checkpoint ***\n",
      "==================== Epoch 1 took 2000.0136811733246s====================\n",
      "Current lr: \t0.001\n",
      "Train\tEpoch: 2\n",
      "Epoch: 2\tBatch: 0\tTimestamp: 0.9399290084838867\n",
      "Epoch: 2\tBatch: 1000\tTimestamp: 515.9370512962341\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-654eed97573f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstartTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train\\tEpoch: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhyper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classify Train \\tEpoch: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-258-0213cf537508>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# clear computation cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model for N epochs\n",
    "print(\"*** Train the model for N epochs ***\")\n",
    "Train_loss = []\n",
    "Train_acc = []\n",
    "Test_loss = []\n",
    "Test_acc = []\n",
    "for i in range(hyper[\"nEpochs\"]):\n",
    "    for prarm_group in optimizer.param_groups:\n",
    "        print(\"Current lr: \\t{}\".format(prarm_group[\"lr\"]))\n",
    "    startTime = time.time()\n",
    "    print(\"Train\\tEpoch: {}\".format(i))\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, i)\n",
    "    if hyper[\"task\"] == \"Classification\":\n",
    "        print(\"Classify Train \\tEpoch: {}\".format(i))\n",
    "        train_loss, train_acc = testClassify(model, train_loader, i)\n",
    "        print(\"Classify Dev \\tEpoch: {}\".format(i))\n",
    "        dev_loss, dev_acc = testClassify(model, dev_loader, i)\n",
    "        print('Train Loss: {:.4f}\\tTrain Accuracy: {:.4f}\\tVal Loss: {:.4f}\\tVal Accuracy: {:.4f}'.\n",
    "              format(train_loss, train_acc, dev_loss, dev_acc))\n",
    "    else:\n",
    "        print(\"Verification task\")\n",
    "    scheduler.step(dev_loss)\n",
    "    Train_loss.append(train_loss)\n",
    "    Train_acc.append(train_acc)\n",
    "    Test_loss.append(dev_loss)\n",
    "    Test_acc.append(dev_acc)\n",
    "    print(\"*** Saving Checkpoint ***\")\n",
    "    path = \"{}ContContContInitWeight_BaselineSGD_StepLR_Epoch{}.txt\".format(wegithDirName, i)\n",
    "    torch.save({\n",
    "        \"epoch\": i,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        'dev_loss':dev_loss,\n",
    "        'dev_acc': dev_acc\n",
    "    }, path)\n",
    "    print(\"=\"*20 + \" Epoch {} took {}s\".format(i, time.time()-startTime) + \"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72.15217391304348,\n",
       " 71.78260869565217,\n",
       " 71.67391304347827,\n",
       " 72.34782608695653,\n",
       " 72.60869565217392,\n",
       " 72.34782608695653,\n",
       " 72.54347826086956,\n",
       " 72.26086956521739,\n",
       " 72.3913043478261]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writeout test labels\n",
    "labels = predictLabels(model, test_loader)\n",
    "labels = list(map(int, labels))\n",
    "idxs = np.array(test.getFileList())\n",
    "labels = np.array(labels)\n",
    "# create mappings of file set labels to true labels\n",
    "alphabetSorted = sorted([str(x) for x in range(0, 2300)])\n",
    "filesetTrueLabelTuple = [(i, int(alphabetSorted[i])) for i in range(len(alphabetSorted))]\n",
    "mapping = dict(filesetTrueLabelTuple)\n",
    "labels = np.array(list(map(mapping.get, labels)))\n",
    "np.save(hyper[\"testClassLabelName\"], labels)\n",
    "df = pd.DataFrame({\"Id\" : idxs, \"Category\" : labels})\n",
    "df.to_csv(hyper[\"testClassLabelCSVfn\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in verification pairs for validation\n",
    "verifyData_valid = MyDatasetVerify(hyper[\"verifyPairListPath\"], hyper[\"verifyImgFolderPath\"])\n",
    "verify_loader_args_valid = dict(shuffle=False, batch_size=200, num_workers=8, pin_memory=True)\n",
    "verify_loader_valid = DataLoader(verifyData_valid, **verify_loader_args_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification validation data stat: 100000 pairs \t\n"
     ]
    }
   ],
   "source": [
    "print(\"Verification validation data stat: {} pairs \\t\".format(verifyData_valid.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\t Timestamp:0.8667874336242676\n",
      "Batch: 100\t Timestamp:16.919691801071167\n",
      "Batch: 200\t Timestamp:33.428550004959106\n",
      "Batch: 300\t Timestamp:50.103861570358276\n",
      "Batch: 400\t Timestamp:66.74586343765259\n",
      "*** AUC: 0.9401668958798193 ***\n"
     ]
    }
   ],
   "source": [
    "# Calculate simliarity score\n",
    "cosScore_valid, trueScore_valid = testVerify(model, verify_loader_valid)\n",
    "\n",
    "# Report AUC\n",
    "auc = roc_auc_score(trueScore_valid, cosScore_valid)\n",
    "print(\"*** AUC: {} ***\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in verification pairs for test\n",
    "verifyData_test = MyDatasetVerify(hyper[\"verifyTestPairListPath\"], hyper[\"verifyTestImgFolderPath\"])\n",
    "verify_loader_args_test = dict(shuffle=False, batch_size=300, num_workers=8, pin_memory=True)\n",
    "verify_loader_test = DataLoader(verifyData_test, **verify_loader_args_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification test data stat: 899965 pairs \t\n"
     ]
    }
   ],
   "source": [
    "print(\"Verification test data stat: {} pairs \\t\".format(verifyData_test.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\t Timestamp:1.4902324676513672\n",
      "Batch: 100\t Timestamp:28.6463360786438\n",
      "Batch: 200\t Timestamp:56.59016489982605\n",
      "Batch: 300\t Timestamp:84.8301374912262\n",
      "Batch: 400\t Timestamp:112.83456826210022\n",
      "Batch: 500\t Timestamp:140.91132235527039\n",
      "Batch: 600\t Timestamp:169.0271396636963\n",
      "Batch: 700\t Timestamp:197.16711831092834\n",
      "Batch: 800\t Timestamp:225.24022388458252\n",
      "Batch: 900\t Timestamp:253.30145454406738\n",
      "Batch: 1000\t Timestamp:281.33954644203186\n",
      "Batch: 1100\t Timestamp:309.18132305145264\n",
      "Batch: 1200\t Timestamp:337.0060164928436\n",
      "Batch: 1300\t Timestamp:364.8084807395935\n",
      "Batch: 1400\t Timestamp:392.5616104602814\n",
      "Batch: 1500\t Timestamp:420.29006719589233\n",
      "Batch: 1600\t Timestamp:448.0446226596832\n",
      "Batch: 1700\t Timestamp:475.78411889076233\n",
      "Batch: 1800\t Timestamp:503.5323119163513\n",
      "Batch: 1900\t Timestamp:531.2998230457306\n",
      "Batch: 2000\t Timestamp:559.0744941234589\n",
      "Batch: 2100\t Timestamp:586.861249923706\n",
      "Batch: 2200\t Timestamp:614.6070256233215\n",
      "Batch: 2300\t Timestamp:642.3246262073517\n",
      "Batch: 2400\t Timestamp:670.0901477336884\n",
      "Batch: 2500\t Timestamp:697.8853771686554\n",
      "Batch: 2600\t Timestamp:725.6867926120758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f80d3694cf8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8136210198>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f80d3694cf8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8136210198>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f80d3694cf8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8136210198>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f80d3694cf8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8136210198>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f80d3694cf8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8136210198>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f80d3694cf8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8136210198>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f80d3694cf8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8136210198>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f80d3694cf8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8136210198>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2700\t Timestamp:753.4510560035706\n",
      "Batch: 2800\t Timestamp:781.204389333725\n",
      "Batch: 2900\t Timestamp:808.9699437618256\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity score\n",
    "cosScore_test, _ = testVerify(model, verify_loader_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899965"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cosScore_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictied similarity\n",
    "cosScore_test = np.array(cosScore_test)\n",
    "np.save(hyper[\"testVeriLabelName\"], cosScore_test)\n",
    "trial = np.array(verifyData_test.getPairList())\n",
    "df = pd.DataFrame({\"trial\" : trial, \"score\" : cosScore_test})\n",
    "df.to_csv(hyper[\"testVeriLabelCSVfn\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262615.jpg 207587.jpg</td>\n",
       "      <td>0.357082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120800.jpg 162540.jpg</td>\n",
       "      <td>0.367260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200386.jpg 117646.jpg</td>\n",
       "      <td>0.414564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>268346.jpg 264478.jpg</td>\n",
       "      <td>0.296321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171295.jpg 143107.jpg</td>\n",
       "      <td>0.337177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   trial     score\n",
       "0  262615.jpg 207587.jpg  0.357082\n",
       "1  120800.jpg 162540.jpg  0.367260\n",
       "2  200386.jpg 117646.jpg  0.414564\n",
       "3  268346.jpg 264478.jpg  0.296321\n",
       "4  171295.jpg 143107.jpg  0.337177"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def main(hyper):\n",
    "    dataFolder = hyper['dataPath']\n",
    "    wegithDirName = hyper['weightDirName']\n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "    print(\"*** Load raw data ***\")\n",
    "    train = datasets.ImageFolder(root=dataFolder+\"/train_data/medium\",\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor()]))\n",
    "\n",
    "    dev = datasets.ImageFolder(root=dataFolder+\"/validation_classification/medium\",\n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "    # Load custom dataset for test since it does not follow ImageFolder structure\n",
    "    test = MyDatasetTestClassify(hyper[\"classifyTestListPath\"], hyper[\"classifyTestImgFolderPath\"])\n",
    "\n",
    "    print(\"train data stat: {} images \\t {} classes\".format(train.__len__(), len(train.classes)))\n",
    "    print(\"dev data stat: {} images \\t {} classes\".format(dev.__len__(), len(dev.classes)))\n",
    "    print(\"test data stat: {} images\".format(train.__len__()))\n",
    "\n",
    "    # Get data loaders\n",
    "    train_loader, dev_loader, test_loader = getLoaders(train, dev, test, hyper[\"batchSize\"])\n",
    "    \n",
    "    # Create the model and define the Loss and Optimizer\n",
    "    print(\"*** Create the model and define  Loss and Optimizer ***\")\n",
    "    inputSize = train.__len__()         # number of train input images\n",
    "    outputSize = len(train.classes)     # number of unique face classes\n",
    "    model = Network(inputSize, hyper[\"hiddenDims\"], outputSize)\n",
    "    checkpoint = torch.load(hyper[\"checkpoingPath\"])\n",
    "    # model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=hyper[\"lr\"], momentum=0.9,\\\n",
    "                          nesterov=True, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=2)\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.9, step_size=1)\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "    model.cuda()\n",
    "    print(model)\n",
    "    \n",
    "    # Train the model for N epochs\n",
    "    print(\"*** Train the model for N epochs ***\")\n",
    "    Train_loss = []\n",
    "    Test_loss = []\n",
    "    Test_acc = []\n",
    "    for i in range(hyper[\"nEpochs\"]):\n",
    "        print(\"Training\\tEpoch: {}\".format(i))\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        print(\"Dev\\tEpoch: {}\".format(i))\n",
    "        if hyper[\"task\"] == \"Classification\":\n",
    "            train_loss, train_acc = testClassify(model, train_loader)\n",
    "            dev_loss, dev_acc = testClassify(model, dev_loader)\n",
    "            print('Train Loss: {:.4f}\\tTrain Accuracy: {:.4f}\\tVal Loss: {:.4f}\\tVal Accuracy: {:.4f}'.\n",
    "                  format(train_loss, train_acc, val_loss, val_acc))\n",
    "        else:\n",
    "            print(\"Verification task\")\n",
    "        scheduler.step(dev_loss)\n",
    "        Train_loss.append(train_loss)\n",
    "        Test_loss.append(dev_loss)\n",
    "        Test_acc.append(dev_acc)\n",
    "        print(\"=\"*20)\n",
    "        print(\"*** Saving Checkpoing ***\")\n",
    "        path = \"{}InitWeight_BaselineSGD_StepLR_Epoch{}.txt\".format(wegithDirName, i)\n",
    "        torch.save({\n",
    "            \"epoch\": i,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'dev_loss':dev_loss,\n",
    "            'dev_acc': dev_acc\n",
    "        }, path)\n",
    "        \n",
    "    # Visualizing Training and Validation data\n",
    "    print(\"*** Visualizing Training and Validation Data ***\")\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch Number')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(Train_loss)\n",
    "    plt.savefig(\"Train_Vis.png\")\n",
    "    \n",
    "    plt.title('Dev Accuracy')\n",
    "    plt.xlabel('Epoch Number')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.plot(Test_acc)\n",
    "    plt.savefig(\"Dev_Vis.png\")\n",
    "    \n",
    "    # Writeout test labels\n",
    "    labels = predictLabels(model, test_loader)\n",
    "    labels = list(map(int, labels))\n",
    "    idxs = np.array(test.getFileList())\n",
    "    labels = np.array(labels)\n",
    "    # create mappings of file set labels to true labels\n",
    "    alphabetSorted = sorted([str(x) for x in range(0, 2300)])\n",
    "    filesetTrueLabelTuple = [(i, int(alphabetSorted[i])) for i in range(len(alphabetSorted))]\n",
    "    mapping = dict(filesetTrueLabelTuple)\n",
    "    labels = np.array(list(map(mapping.get, labels)))\n",
    "    np.save(hyper[\"testLabelName\"], labels)\n",
    "    df = pd.DataFrame({\"Id\" : idxs, \"Category\" : labels})\n",
    "    df.to_csv(hyper[\"testLabelCSVfn\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs1E = torch.abs(torch.randn(2, 1, 50))\n",
    "imgs2E = torch.abs(torch.randn(2, 1, 50))\n",
    "res1 = F.cosine_similarity(imgs1E, imgs2E, 1)\n",
    "print(res1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
